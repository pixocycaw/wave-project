# GUARDIÁN IA con GFT

## Enunciado del Reto

Diseñar un sistema capaz de evaluar la calidad de las respuestas proporcionadas por modelos de lenguaje, permitiendo identificar respuestas incorrectas, alucinaciones, sesgadas o inapropiadas. El propósito es mejorar la confianza y eficacia de las interacciones entre humanos y sistemas de inteligencia artificial.

Vuestro reto tendrá que centrarse en:

**Diseñar un sistema capaz de evaluar la calidad de las respuestas proporcionadas por modelos de lenguaje, permitiendo identificar respuestas incorrectas, alucinaciones, sesgadas o inapropiadas. El propósito es mejorar la confianza y eficacia de las interacciones entre humanos y sistemas de inteligencia artificial.**

Ejemplos:

- Evaluación de perplejidad: Mide la capacidad de un modelo para predecir una secuencia de palabras, siendo una métrica común en la evaluación de modelos de lenguaje.
- Conjuntos de datos adversariales: Diseñados para identificar debilidades en los modelos, como el conjunto TruthfulQA, que evalúa la tendencia de los modelos a replicar falsedades comunes.